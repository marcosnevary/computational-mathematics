{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Atividade 2 - Gradiente Descendente**",
   "id": "328a309d87943af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')"
   ],
   "id": "90498febbe19af09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "from src.utils.animate_gradient_descent import animate_gradient_descent\n",
    "from IPython.display import HTML"
   ],
   "id": "e4ad0c3beac6cfbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Código para Letra A e B",
   "id": "ebf77cf9781dc102"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Usando os dados obtidos através do slide, temos os valores de `height` (eixo $x$) e `weight` (eixo $y$) de cada um ponto dos três pontos.",
   "id": "b99e9e840b5d8445"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "heights = [1.4, 1.9, 3.2]\n",
    "weights = [0.5, 2.3, 2.9]"
   ],
   "id": "5f77969551ab1f0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, x_data, y_data, optimize_slope, stochastic):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.x_values = []\n",
    "        self.y_values = []\n",
    "\n",
    "        self.intercept = 0\n",
    "        self.slope = 0.5 if optimize_slope else 0.64\n",
    "        self.optimize_slope = optimize_slope\n",
    "\n",
    "        self.stochastic = stochastic\n",
    "\n",
    "        self.intercept_history = []\n",
    "        self.ssr_history = []\n",
    "        self.slope_gradient_history = []\n",
    "        self.intercept_gradient_history = []\n",
    "        self.x_values_history = []\n",
    "        self.y_values_history = []\n",
    "\n",
    "        if self.optimize_slope:\n",
    "            self.slope_history = []\n",
    "\n",
    "    def _compute_ssr_and_gradient(self, slope, intercept):\n",
    "        ssr = 0\n",
    "        gradient_slope = 0\n",
    "        gradient_intercept = 0\n",
    "\n",
    "        self.x_values = self.x_data\n",
    "        self.y_values = self.y_data\n",
    "\n",
    "        if self.stochastic:\n",
    "            self.x_values = []\n",
    "            self.y_values = []\n",
    "            i, j = random.sample(range(len(self.x_data)), 2)\n",
    "            self.x_values.append(self.x_data[i])\n",
    "            self.x_values.append(self.x_data[j])\n",
    "            self.y_values.append(self.y_data[i])\n",
    "            self.y_values.append(self.y_data[j])\n",
    "\n",
    "        for x, y in zip(self.x_values, self.y_values):\n",
    "            prediction = slope * x + intercept\n",
    "            residual = y - prediction\n",
    "\n",
    "            ssr += residual ** 2\n",
    "            gradient_slope += -2 * x * residual\n",
    "            gradient_intercept += -2 * residual\n",
    "\n",
    "        return ssr, gradient_slope, gradient_intercept\n",
    "\n",
    "    def _update_intercept(self, learning_rate, gradient_intercept):\n",
    "        step = learning_rate * gradient_intercept\n",
    "        self.intercept -= step\n",
    "        return step\n",
    "\n",
    "    def _update_slope(self, learning_rate, gradient_slope):\n",
    "        step = learning_rate * gradient_slope\n",
    "        self.slope -= step\n",
    "        return step\n",
    "\n",
    "    def gradient_descent(self, learning_rate, max_iterations, goal):\n",
    "        for iteration in range(max_iterations):\n",
    "            ssr, gradient_slope, gradient_intercept = self._compute_ssr_and_gradient(\n",
    "                self.slope, self.intercept\n",
    "            )\n",
    "\n",
    "            self.intercept_history.append(self.intercept)\n",
    "            self.ssr_history.append(ssr)\n",
    "            self.slope_gradient_history.append(gradient_slope)\n",
    "            self.intercept_gradient_history.append(gradient_intercept)\n",
    "            self.x_values_history.append(self.x_values)\n",
    "            self.y_values_history.append(self.y_values)\n",
    "\n",
    "            print(f\"Iteração {iteration + 1} ========================================\")\n",
    "            print(f\"Intercept Antigo: {self.intercept}\")\n",
    "\n",
    "            intercept_step = self._update_intercept(learning_rate, gradient_intercept)\n",
    "            print(f\"Tamanho do Passo (Intercept): {intercept_step}\")\n",
    "            print(f\"Intercept Novo: {self.intercept}\")\n",
    "\n",
    "            if self.optimize_slope:\n",
    "                self.slope_history.append(self.slope)\n",
    "                print(\"----------------------------------------------------\")\n",
    "                print(f\"Slope Antigo: {self.slope}\")\n",
    "                slope_step = self._update_slope(learning_rate, gradient_slope)\n",
    "                print(f\"Tamanho do Passo (Slope): {slope_step}\")\n",
    "                print(f\"Slope Novo: {self.slope}\")\n",
    "\n",
    "            if ssr < goal:\n",
    "                break"
   ],
   "id": "9b84849b8d1a3f7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Letra A",
   "id": "4f140b01cef63f2b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Em seguida, iremos realizar a regressão linear com gradiente descendente usando `learning_rate = 0.01` e considerando apenas a otimização do intercept.",
   "id": "a4e989a4ac8eb6a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "linear_regression = LinearRegression(weights, heights, False, False)\n",
    "linear_regression.gradient_descent(0.01, 100, 0.45)\n",
    "animation = animate_gradient_descent(linear_regression)\n",
    "\n",
    "HTML(animation.to_jshtml())"
   ],
   "id": "d29aa38d430c472a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Em seguida, iremos realizar a regressão linear com gradiente descendente usando `learning_rate = 0.3` e considerando apenas a otimização do intercept.",
   "id": "6671f5f9763d010e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "linear_regression = LinearRegression(weights, heights, False, False)\n",
    "linear_regression.gradient_descent(0.3, 100, 0.45)\n",
    "animation = linear_regression.animate()\n",
    "\n",
    "HTML(animation.to_jshtml())"
   ],
   "id": "a85d46adf627ddb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pelos gráficos, podemos perceber que mesmo usando diferentes valores para o `learning_rate` o gradiente descendente convergiu para o valor ótimo do intercept. Entretanto, usando um `learning_rate` maior o algoritmo realizou 15 iterações, enquanto com `learning_rate` menor realizou 52 iterações. É importante mencionar que usar um `learning_rate` maior, apesar de trazer resultados mais rápidos, pode não convergir para o intercept ótimo devido aos overshoots. Além disso, como estamos otimizando apenas o valor do intercept a reta que está sendo ajustada aos dados varia apenas verticalmente a cada iteração.",
   "id": "296142565efecb0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Letra B (Parte 1)",
   "id": "7344d1b5977a51be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Primeiramente, iremos realizar a regressão linear com gradiente descendente usando `learning_rate = 0.01` e considerando a otimização do slope e intercept.",
   "id": "94557487651fed71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "linear_regression = LinearRegression(weights, heights, True, False)\n",
    "linear_regression.gradient_descent(0.01, 100, 0.45)\n",
    "animation = linear_regression.animate()\n",
    "\n",
    "HTML(animation.to_jshtml())"
   ],
   "id": "5fbefd58f73dfe3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Em seguida, iremos realizar a regressão linear com gradiente descendente usando `learning_rate = 0.3` e considerando a otimização do slope e intercept.",
   "id": "903478e359a6f835"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "linear_regression = LinearRegression(weights, heights, True, False)\n",
    "linear_regression.gradient_descent(0.3, 100, 0.45)\n",
    "animation = linear_regression.animate()\n",
    "\n",
    "HTML(animation.to_jshtml())"
   ],
   "id": "c1fc52f91dd9e4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pelos gráficos, podemos perceber que o algoritmo que usou o `learning_rate` menor conseguiu ajustar uma reta ótima aos dados fornecidos, enquanto o que usou o `learning_rate` maior divergiu e não conseguiu ajustar uma reta aos dados. Esse comportamento do segundo algoritmo se dá devido aos overshoots. Além disso, como estamos otimizando tanto o slope quanto o intercept, a reta que se ajusta aos dados varia tanto em inclinação quando em coisa vertical a cada iteração.",
   "id": "ef58141c63d237fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Letra B (Parte 2)",
   "id": "9c7b9ffcad9ef3d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Em seguida, iremos realizar a regressão linear com gradiente descendente estocástico usando `learning_rate = 0.01` e considerando apenas a otimização do intercept.",
   "id": "e9a6beb24d014b36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "linear_regression = LinearRegression(weights, heights, False, True)\n",
    "linear_regression.gradient_descent(0.01, 100, 0.45)\n",
    "animation = linear_regression.animate()\n",
    "\n",
    "HTML(animation.to_jshtml())"
   ],
   "id": "b45a672ee1713a3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Em seguida, iremos realizar a regressão linear com gradiente descendente estocástico usando `learning_rate = 0.3` e considerando apenas a otimização do intercept.",
   "id": "486e39bb30e9c0e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "linear_regression = LinearRegression(weights, heights, False, True)\n",
    "linear_regression.gradient_descent(0.3, 100, 0.45)\n",
    "animation = linear_regression.animate()\n",
    "\n",
    "HTML(animation.to_jshtml())"
   ],
   "id": "f69c2564cff8a725",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pelos gráficos, observa-se que a reta do primeiro se ajusta lentamente aos dados porém o algoritmo é encerrado antes que ela se ajuste totalmente pois o erro posto como objetivo foi de `0.45`, enquanto o segundo executa apenas 2 iterações e encerra após chegar no erro objetivo.",
   "id": "2c0616c186431365"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Para visualizar melhor o comportamento do gradiente descendente estocástico, ajustamentos o `learning_rate` para `0.01` e o `goal` para `0.2`.",
   "id": "d47da8a82627a1f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "linear_regression = LinearRegression(weights, heights, False, True)\n",
    "linear_regression.gradient_descent(0.01, 100, 0.2)\n",
    "animation = linear_regression.animate()\n",
    "\n",
    "HTML(animation.to_jshtml())"
   ],
   "id": "f89af310ab423f06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Observe que agora mais iterações são executados pelo algoritmo e a reta é ajustada corretamente aos dados ao longo de cada iteração.",
   "id": "207a91f153440698"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
